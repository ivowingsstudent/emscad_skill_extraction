{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Ivo/emscad-skill-extraction-conference-token-classification and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n",
    "\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "embedding = TransformerWordEmbeddings('Ivo/emscad-skill-extraction-conference-token-classification')\n",
    "\n",
    "#bert-large-uncased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_context</th>\n",
       "      <th>recovered_gram</th>\n",
       "      <th>right_context</th>\n",
       "      <th>label</th>\n",
       "      <th>concatenated</th>\n",
       "      <th>concatenated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be look for a temporary opportunity within a p...</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>environment please forward your cv today</td>\n",
       "      <td>0</td>\n",
       "      <td>be look for a temporary opportunity within a p...</td>\n",
       "      <td>be look for a temporary opportunity within a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for over 30 year this client be a lead</td>\n",
       "      <td>independent</td>\n",
       "      <td>supplier of bespeak product and solution to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>for over 30 year this client be a lead  | inde...</td>\n",
       "      <td>for over 30 year this client be a lead  | inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you will be responsible for lead the clinical ...</td>\n",
       "      <td>team working</td>\n",
       "      <td>be</td>\n",
       "      <td>0</td>\n",
       "      <td>you will be responsible for lead the clinical ...</td>\n",
       "      <td>you will be responsible for lead the clinical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfi rfp bid</td>\n",
       "      <td>proposal writing</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>rfi rfp bid  | proposal writing | empty</td>\n",
       "      <td>rfi rfp bid  | proposal writing | empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>travel managementstrong analytical and organis...</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>and proactive in your sale approach with a re...</td>\n",
       "      <td>0</td>\n",
       "      <td>travel managementstrong analytical and organis...</td>\n",
       "      <td>travel managementstrong analytical and organis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        left_context    recovered_gram  \\\n",
       "0  be look for a temporary opportunity within a p...           dynamic   \n",
       "1            for over 30 year this client be a lead        independent   \n",
       "2  you will be responsible for lead the clinical ...      team working   \n",
       "3                                       rfi rfp bid   proposal writing   \n",
       "4  travel managementstrong analytical and organis...           dynamic   \n",
       "\n",
       "                                       right_context  label  \\\n",
       "0           environment please forward your cv today      0   \n",
       "1   supplier of bespeak product and solution to t...      0   \n",
       "2                                                 be      0   \n",
       "3                                              empty      0   \n",
       "4   and proactive in your sale approach with a re...      0   \n",
       "\n",
       "                                        concatenated  \\\n",
       "0  be look for a temporary opportunity within a p...   \n",
       "1  for over 30 year this client be a lead  | inde...   \n",
       "2  you will be responsible for lead the clinical ...   \n",
       "3            rfi rfp bid  | proposal writing | empty   \n",
       "4  travel managementstrong analytical and organis...   \n",
       "\n",
       "                                       concatenated2  \n",
       "0  be look for a temporary opportunity within a p...  \n",
       "1  for over 30 year this client be a lead  | inde...  \n",
       "2  you will be responsible for lead the clinical ...  \n",
       "3            rfi rfp bid  | proposal writing | empty  \n",
       "4  travel managementstrong analytical and organis...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ivowings/Sync/Thesis/Datasources/Conference data/conference_data.csv',sep=',')\n",
    "df = df.fillna('')\n",
    "df['concatenated'] = df['left_context'] + ' | ' + df['recovered_gram'] + ' | ' + df['right_context']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_embedder(text,label):\n",
    "\n",
    "    label = label\n",
    "    string = Sentence(text)\n",
    "    embedding.embed(string)\n",
    "\n",
    "\n",
    "    # Creating a list which stores the indexes of the | symbols\n",
    "    bar_indexes_skill = []\n",
    "    #Creating a list which stores the embeddings_tensors_skill\n",
    "    embeddings_tensors_skill = []\n",
    "    #Creating a list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    #Checking the sentence object for the | symbols and storing their indexes\n",
    "    for x in range(1,len(string)+1):\n",
    "        if '|' in str(string.get_token(x)):\n",
    "            bar_indexes_skill.append(x)\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    #Collecting the embeddings for every index between the indexes in bar_indexes_skill\n",
    "    word_embedding_indexes = range(bar_indexes_skill[0],bar_indexes_skill[1]-1)\n",
    "    for x in word_embedding_indexes:\n",
    "        embeddings_tensors_skill.append(pd.Series(string[x].embedding))\n",
    "        token_list.append(string[x].text)\n",
    "\n",
    "    #Turning the elements from embeddings_tensors_skill into dataframe rows\n",
    "    row_skill = pd.DataFrame()\n",
    "    for x in range(0,len(embeddings_tensors_skill)):\n",
    "        indi_row = pd.DataFrame(pd.Series(embeddings_tensors_skill[x]))\n",
    "        indi_row = indi_row.transpose()\n",
    "        row_skill = pd.concat([row_skill,indi_row])\n",
    "\n",
    "    #Changing the column names in order to make pd.concat work later\n",
    "    row_skill.columns = [x for x in range(0,len(row_skill.columns))]\n",
    "    row_skill['label'] = label\n",
    "    row_skill['token'] = token_list\n",
    "\n",
    "    #This section converts all non labeled tokens into seperate bert embeddings\n",
    "\n",
    "    # Creating a list which stores the indexes of the | symbols\n",
    "    bar_indexes = []\n",
    "    #Creating a list which stores the embedding_tensors\n",
    "    embedding_tensors2 = []\n",
    "    #Creating a list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    #Checking the sentence object for the | symbols and storing their indexes\n",
    "    for x in range(1,len(string)+1):\n",
    "        if '|' in str(string.get_token(x)):\n",
    "            bar_indexes.append(x)\n",
    "\n",
    "    #Collecting the embeddings for every index between the indexes in bar_indexes\n",
    "    word_embedding_indexes = range(bar_indexes[0]-1,bar_indexes[1])\n",
    "    banaan = range(0,len(string))\n",
    "\n",
    "    other_words = [x for x in banaan if x not in word_embedding_indexes]\n",
    "    #other_words = [0,1]\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    for x in other_words:\n",
    "        embedding_tensors2.append(pd.Series(string[x].embedding))\n",
    "        token_list.append(string[x].text)\n",
    "\n",
    "\n",
    "    #Turning the elements from embedding_tensors into dataframe rows\n",
    "    row = pd.DataFrame()\n",
    "    for x in range(0,len(embedding_tensors2)):\n",
    "        indi_row = pd.DataFrame(pd.Series(embedding_tensors2[x]))\n",
    "        indi_row = indi_row.transpose()\n",
    "        row = pd.concat([row,indi_row])\n",
    "\n",
    "    row['label'] = 0\n",
    "    row['token'] = token_list\n",
    "\n",
    "    final_row = pd.concat([row_skill,row]).reset_index(drop=True)\n",
    "    return final_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = pd.DataFrame()\n",
    "\n",
    "for text,label in tqdm(zip(df['concatenated'],df['label'])):\n",
    "    bert_embeddings = pd.concat([bert_embeddings,bert_embedder(text,label)])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "bert_embeddings = shuffle(bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bert = bert_embeddings.drop(columns=['token','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 55.5min finished\n",
      " 17%|█▋        | 1/6 [55:31<4:37:39, 3331.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 412.9min finished\n",
      " 33%|███▎      | 2/6 [7:48:24<17:42:57, 15944.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.2min finished\n",
      " 50%|█████     | 3/6 [7:49:36<7:14:49, 8696.45s/it]  [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 241.6min finished\n",
      " 67%|██████▋   | 4/6 [11:51:10<6:06:10, 10985.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 111.6min finished\n",
      " 83%|████████▎ | 5/6 [13:42:45<2:37:18, 9438.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  9.5min finished\n",
      "100%|██████████| 6/6 [13:52:18<00:00, 8323.00s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 24.2 s, total: 31.2 s\n",
      "Wall time: 13h 52min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.880810</td>\n",
       "      <td>0.864470</td>\n",
       "      <td>0.872208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.334281</td>\n",
       "      <td>0.421515</td>\n",
       "      <td>0.344317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.909848</td>\n",
       "      <td>0.843280</td>\n",
       "      <td>0.872815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.923061</td>\n",
       "      <td>0.633686</td>\n",
       "      <td>0.693682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.920099</td>\n",
       "      <td>0.842557</td>\n",
       "      <td>0.876206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.871169</td>\n",
       "      <td>0.860620</td>\n",
       "      <td>0.865103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.880810  0.864470  0.872208\n",
       "1        GBC   0.334281  0.421515  0.344317\n",
       "2        SGD   0.909848  0.843280  0.872815\n",
       "3         RF   0.923061  0.633686  0.693682\n",
       "4        SVM   0.920099  0.842557  0.876206\n",
       "5        MLP   0.871169  0.860620  0.865103"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "functions.model_performance(x_bert, bert_embeddings['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205245/205245 [15:03<00:00, 227.13it/s]\n",
      "100%|██████████| 205245/205245 [14:55<00:00, 229.14it/s]\n",
      "100%|██████████| 205245/205245 [14:52<00:00, 230.05it/s]\n",
      "100%|██████████| 205245/205245 [4:42:39<00:00, 12.10it/s]    \n"
     ]
    }
   ],
   "source": [
    "x_bert = bert_embeddings.reset_index(drop=True)\n",
    "\n",
    "x_bert['pos'] = x_bert['token'].progress_apply(functions.pos_tagger)\n",
    "x_bert['pos'] = x_bert['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "pos_dicts = x_bert[['pos']]\n",
    "pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_bert['dep'] = x_bert['token'].progress_apply(functions.dep_tagger)\n",
    "x_bert['dep'] = x_bert['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "dep_dicts = x_bert[['dep']]\n",
    "dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_pos = pos_dicts.join(dep_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "\n",
    "x = x_bert.drop(columns=['token','label','pos','dep']).join(x_pos, lsuffix='_embedding', rsuffix='_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 170.3min finished\n",
      " 17%|█▋        | 1/6 [2:50:16<14:11:24, 10216.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 470.5min finished\n",
      " 33%|███▎      | 2/6 [10:40:49<23:07:37, 20814.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.8min finished\n",
      " 50%|█████     | 3/6 [10:43:36<9:29:18, 11386.20s/it] [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 249.7min finished\n",
      " 67%|██████▋   | 4/6 [14:53:19<7:06:52, 12806.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 116.6min finished\n",
      " 83%|████████▎ | 5/6 [16:49:58<2:58:32, 10712.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  9.8min finished\n",
      "100%|██████████| 6/6 [16:59:47<00:00, 10197.98s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.5 s, sys: 23.7 s, total: 31.2 s\n",
      "Wall time: 16h 59min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.879385</td>\n",
       "      <td>0.861406</td>\n",
       "      <td>0.869882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.334281</td>\n",
       "      <td>0.421515</td>\n",
       "      <td>0.344317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.909934</td>\n",
       "      <td>0.844978</td>\n",
       "      <td>0.873543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.631489</td>\n",
       "      <td>0.691054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.921364</td>\n",
       "      <td>0.842080</td>\n",
       "      <td>0.876416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.872919</td>\n",
       "      <td>0.865523</td>\n",
       "      <td>0.868368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.879385  0.861406  0.869882\n",
       "1        GBC   0.334281  0.421515  0.344317\n",
       "2        SGD   0.909934  0.844978  0.873543\n",
       "3         RF   0.934330  0.631489  0.691054\n",
       "4        SVM   0.921364  0.842080  0.876416\n",
       "5        MLP   0.872919  0.865523  0.868368"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "functions.model_performance(x.fillna(0.0), bert_embeddings['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
