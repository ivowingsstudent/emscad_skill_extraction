{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from flair.data import Sentence\n",
    "\n",
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = ELMoEmbeddings('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Combined/Taxonomy/Normal/Annotated/combined_annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated rows  20836\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations,sep=';')\n",
    "\n",
    "#Filling any empty context columns with 'empty'\n",
    "df['left_context'] = df['left_context'].fillna('empty')\n",
    "df['right_context'] = df['right_context'].fillna('empty')\n",
    "\n",
    "df['concatenated'] = df['left_context'] + ' | ' + df['candidate_skill'] + ' | ' + df['right_context']\n",
    "print('Number of annotated rows ',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMo_embedder(text,label):\n",
    "\n",
    "    label = label\n",
    "    string = Sentence(text)\n",
    "    embedding.embed(string)\n",
    "\n",
    "\n",
    "    # Creating a list which stores the indexes of the | symbols\n",
    "    bar_indexes_skill = []\n",
    "    #Creating a list which stores the embeddings_tensors_skill\n",
    "    embeddings_tensors_skill = []\n",
    "    #Creating a list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    #Checking the sentence object for the | symbols and storing their indexes\n",
    "    for x in range(1,len(string)+1):\n",
    "        if '|' in str(string.get_token(x)):\n",
    "            bar_indexes_skill.append(x)\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    #Collecting the embeddings for every index between the indexes in bar_indexes_skill\n",
    "    word_embedding_indexes = range(bar_indexes_skill[0],bar_indexes_skill[1]-1)\n",
    "    for x in word_embedding_indexes:\n",
    "        embeddings_tensors_skill.append(pd.Series(string[x].embedding))\n",
    "        token_list.append(string[x].text)\n",
    "\n",
    "    #Turning the elements from embeddings_tensors_skill into dataframe rows\n",
    "    row_skill = pd.DataFrame()\n",
    "    for x in range(0,len(embeddings_tensors_skill)):\n",
    "        indi_row = pd.DataFrame(pd.Series(embeddings_tensors_skill[x]))\n",
    "        indi_row = indi_row.transpose()\n",
    "        row_skill = pd.concat([row_skill,indi_row])\n",
    "\n",
    "    #Changing the column names in order to make pd.concat work later\n",
    "    row_skill.columns = [x for x in range(0,len(row_skill.columns))]\n",
    "    row_skill['label'] = label\n",
    "    row_skill['token'] = token_list\n",
    "\n",
    "    #This section converts all non labeled tokens into seperate bert embeddings\n",
    "\n",
    "    # Creating a list which stores the indexes of the | symbols\n",
    "    bar_indexes = []\n",
    "    #Creating a list which stores the embedding_tensors\n",
    "    embedding_tensors2 = []\n",
    "    #Creating a list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    #Checking the sentence object for the | symbols and storing their indexes\n",
    "    for x in range(1,len(string)+1):\n",
    "        if '|' in str(string.get_token(x)):\n",
    "            bar_indexes.append(x)\n",
    "\n",
    "    #Collecting the embeddings for every index between the indexes in bar_indexes\n",
    "    word_embedding_indexes = range(bar_indexes[0]-1,bar_indexes[1])\n",
    "    banaan = range(0,len(string))\n",
    "\n",
    "    other_words = [x for x in banaan if x not in word_embedding_indexes]\n",
    "    #other_words = [0,1]\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    for x in other_words:\n",
    "        embedding_tensors2.append(pd.Series(string[x].embedding))\n",
    "        token_list.append(string[x].text)\n",
    "\n",
    "\n",
    "    #Turning the elements from embedding_tensors into dataframe rows\n",
    "    row = pd.DataFrame()\n",
    "    for x in range(0,len(embedding_tensors2)):\n",
    "        indi_row = pd.DataFrame(pd.Series(embedding_tensors2[x]))\n",
    "        indi_row = indi_row.transpose()\n",
    "        row = pd.concat([row,indi_row])\n",
    "\n",
    "    row['label'] = 0\n",
    "    row['token'] = token_list\n",
    "\n",
    "    final_row = pd.concat([row_skill,row]).reset_index(drop=True)\n",
    "    return final_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20836it [1:43:22,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "elmo_embeddings = pd.DataFrame()\n",
    "\n",
    "for text,label in tqdm(zip(df['concatenated'],df['label'])):\n",
    "    elmo_embeddings = pd.concat([elmo_embeddings,ELMo_embedder(text,label)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "elmo_embeddings = shuffle(elmo_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_elmo = elmo_embeddings.drop(columns=['token','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 109.5min finished\n",
      " 17%|█▋        | 1/6 [1:49:30<9:07:30, 6570.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 327.0min finished\n",
      " 33%|███▎      | 2/6 [7:16:32<15:49:50, 14247.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      " 50%|█████     | 3/6 [7:18:04<6:29:12, 7784.31s/it]  [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 417.9min finished\n",
      " 67%|██████▋   | 4/6 [14:16:01<8:07:01, 14610.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 340.6min finished\n",
      " 83%|████████▎ | 5/6 [19:56:35<4:38:30, 16710.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 236.1min finished\n",
      "100%|██████████| 6/6 [23:52:43<00:00, 14327.23s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 22.1 s, total: 27.5 s\n",
      "Wall time: 23h 52min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.792410</td>\n",
       "      <td>0.667257</td>\n",
       "      <td>0.717733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.528836</td>\n",
       "      <td>0.364413</td>\n",
       "      <td>0.378067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.787492</td>\n",
       "      <td>0.591499</td>\n",
       "      <td>0.648538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.931601</td>\n",
       "      <td>0.521168</td>\n",
       "      <td>0.593578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.887527</td>\n",
       "      <td>0.590550</td>\n",
       "      <td>0.635641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.694874</td>\n",
       "      <td>0.734249</td>\n",
       "      <td>0.712922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.792410  0.667257  0.717733\n",
       "1        GBC   0.528836  0.364413  0.378067\n",
       "2        SGD   0.787492  0.591499  0.648538\n",
       "3         RF   0.931601  0.521168  0.593578\n",
       "4        SVM   0.887527  0.590550  0.635641\n",
       "5        MLP   0.694874  0.734249  0.712922"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "functions.model_performance(x_elmo, elmo_embeddings['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205777/205777 [23:15<00:00, 147.49it/s]\n",
      "100%|██████████| 205777/205777 [23:54<00:00, 143.47it/s]\n",
      "100%|██████████| 205777/205777 [23:09<00:00, 148.11it/s]\n",
      "100%|██████████| 205777/205777 [23:09<00:00, 148.06it/s]\n"
     ]
    }
   ],
   "source": [
    "x_elmo = elmo_embeddings.reset_index(drop=True)\n",
    "\n",
    "x_elmo['pos'] = x_elmo['token'].progress_apply(functions.pos_tagger)\n",
    "x_elmo['pos'] = x_elmo['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "pos_dicts = x_elmo[['pos']]\n",
    "pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_elmo['dep'] = x_elmo['token'].progress_apply(functions.dep_tagger)\n",
    "x_elmo['dep'] = x_elmo['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "dep_dicts = x_elmo[['dep']]\n",
    "dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_pos = pos_dicts.join(dep_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "\n",
    "x = x_elmo.drop(columns=['token','label','pos','dep']).join(x_pos, lsuffix='_embedding', rsuffix='_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 133.8min finished\n",
      " 17%|█▋        | 1/6 [2:13:46<11:08:50, 8026.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 839.0min finished\n",
      " 33%|███▎      | 2/6 [16:12:46<36:34:27, 32916.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.5min finished\n",
      " 50%|█████     | 3/6 [16:18:15<15:01:50, 18036.78s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 112.9min finished\n",
      " 67%|██████▋   | 4/6 [18:11:10<7:33:01, 13590.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 243.1min finished\n",
      " 83%|████████▎ | 5/6 [22:14:16<3:52:29, 13949.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 104.5min finished\n",
      "100%|██████████| 6/6 [23:58:48<00:00, 14388.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.66 s, sys: 20.1 s, total: 25.8 s\n",
      "Wall time: 23h 58min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.792097</td>\n",
       "      <td>0.670080</td>\n",
       "      <td>0.719886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.528836</td>\n",
       "      <td>0.364413</td>\n",
       "      <td>0.378067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.799346</td>\n",
       "      <td>0.593939</td>\n",
       "      <td>0.646220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.926434</td>\n",
       "      <td>0.523284</td>\n",
       "      <td>0.596734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.887442</td>\n",
       "      <td>0.590163</td>\n",
       "      <td>0.635371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.702307</td>\n",
       "      <td>0.734510</td>\n",
       "      <td>0.717455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.792097  0.670080  0.719886\n",
       "1        GBC   0.528836  0.364413  0.378067\n",
       "2        SGD   0.799346  0.593939  0.646220\n",
       "3         RF   0.926434  0.523284  0.596734\n",
       "4        SVM   0.887442  0.590163  0.635371\n",
       "5        MLP   0.702307  0.734510  0.717455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "functions.model_performance(x.fillna(0.0), elmo_embeddings['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
