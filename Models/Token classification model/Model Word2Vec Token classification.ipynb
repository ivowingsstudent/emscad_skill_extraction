{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "word2vec = api.load(\"glove-wiki-gigaword-300\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Combined/Taxonomy/Normal/Annotated/combined_annotations_token.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>them</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokens  label\n",
       "0       assist      0\n",
       "1        their      0\n",
       "2  development      0\n",
       "3       enable      0\n",
       "4         them      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(annotations,sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "def word2vec_vocab_check(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    try:\n",
    "        word2vec.wv[tokens]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#Function to retrieve word2vec vectors from spacy\n",
    "def word2vec_retriever_sum(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    wordvectors = sum(word2vec.wv[tokens])\n",
    "    return wordvectors\n",
    "    \n",
    "def word2vec_retriever_average(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    wordvectors = word2vec.wv[tokens]\n",
    "    average = sum(wordvectors)/len(wordvectors)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/208742 [00:00<?, ?it/s]<ipython-input-4-cd24b054c66e>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec.wv[tokens]\n",
      "100%|██████████| 208742/208742 [00:03<00:00, 59724.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(206918, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing out of vocabulary word2vec words\n",
    "df['vocab_check'] = df['tokens'].progress_apply(word2vec_vocab_check)\n",
    "df = df[df.vocab_check==True]\n",
    "df = df.drop(columns=['vocab_check'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206918 [00:00<?, ?it/s]<ipython-input-4-cd24b054c66e>:15: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  wordvectors = sum(word2vec.wv[tokens])\n",
      "100%|██████████| 206918/206918 [00:05<00:00, 37270.47it/s]\n",
      "100%|██████████| 206918/206918 [00:44<00:00, 4660.50it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(206918, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = word2vec_retriever_sum\n",
    "\n",
    "#Retrieving the word2vec vectors\n",
    "x = pd.DataFrame(df['tokens'].progress_apply(mode))\n",
    "x = x['tokens'].progress_apply(pd.Series)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 11.8min finished\n",
      " 17%|█▋        | 1/6 [11:49<59:07, 709.51s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 56.1min finished\n",
      " 33%|███▎      | 2/6 [1:07:58<2:31:36, 2274.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   27.5s finished\n",
      " 50%|█████     | 3/6 [1:08:26<1:02:24, 1248.29s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 17.4min finished\n",
      " 67%|██████▋   | 4/6 [1:25:51<38:56, 1168.27s/it]  [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 575.2min finished\n",
      " 83%|████████▎ | 5/6 [11:01:06<3:39:53, 13193.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 13.0min finished\n",
      "100%|██████████| 6/6 [11:14:05<00:00, 6740.92s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 6.67 s, total: 9.85 s\n",
      "Wall time: 11h 14min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.510403</td>\n",
       "      <td>0.341143</td>\n",
       "      <td>0.341378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.425754</td>\n",
       "      <td>0.377324</td>\n",
       "      <td>0.390439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.318608</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.599791</td>\n",
       "      <td>0.376090</td>\n",
       "      <td>0.399973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.590277</td>\n",
       "      <td>0.362385</td>\n",
       "      <td>0.378063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.570847</td>\n",
       "      <td>0.375611</td>\n",
       "      <td>0.399106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.510403  0.341143  0.341378\n",
       "1        GBC   0.425754  0.377324  0.390439\n",
       "2        SGD   0.318608  0.333333  0.325804\n",
       "3         RF   0.599791  0.376090  0.399973\n",
       "4        SVM   0.590277  0.362385  0.378063\n",
       "5        MLP   0.570847  0.375611  0.399106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "functions.model_performance(x, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206918/206918 [14:47<00:00, 233.21it/s] \n",
      "100%|██████████| 206918/206918 [14:49<00:00, 232.68it/s]\n",
      "100%|██████████| 206918/206918 [14:44<00:00, 233.98it/s]\n",
      "100%|██████████| 206918/206918 [14:48<00:00, 232.76it/s]\n"
     ]
    }
   ],
   "source": [
    "df['pos'] = df['tokens'].progress_apply(functions.pos_tagger)\n",
    "df['pos'] = df['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "pos_dicts = df[['pos']]\n",
    "pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "df['dep'] = df['tokens'].progress_apply(functions.dep_tagger)\n",
    "df['dep'] = df['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "dep_dicts = df[['dep']]\n",
    "dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_pos = pos_dicts.join(dep_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "\n",
    "x = x.join(x_pos, lsuffix='_embedding', rsuffix='_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 13.3min finished\n",
      " 17%|█▋        | 1/6 [13:17<1:06:26, 797.38s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 43.9min finished\n",
      " 33%|███▎      | 2/6 [57:14<2:05:17, 1879.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   28.3s finished\n",
      " 50%|█████     | 3/6 [57:42<51:42, 1034.22s/it]  [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 18.8min finished\n",
      " 67%|██████▋   | 4/6 [1:16:31<35:43, 1071.53s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 833.0min finished\n",
      " 83%|████████▎ | 5/6 [15:09:31<5:11:48, 18708.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.6min finished\n",
      "100%|██████████| 6/6 [15:22:09<00:00, 9221.51s/it]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.519362</td>\n",
       "      <td>0.341197</td>\n",
       "      <td>0.341487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.425754</td>\n",
       "      <td>0.377324</td>\n",
       "      <td>0.390439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.318608</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.325803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.604236</td>\n",
       "      <td>0.376094</td>\n",
       "      <td>0.399995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.590984</td>\n",
       "      <td>0.361740</td>\n",
       "      <td>0.377120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.560824</td>\n",
       "      <td>0.374237</td>\n",
       "      <td>0.396754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.519362  0.341197  0.341487\n",
       "1        GBC   0.425754  0.377324  0.390439\n",
       "2        SGD   0.318608  0.333330  0.325803\n",
       "3         RF   0.604236  0.376094  0.399995\n",
       "4        SVM   0.590984  0.361740  0.377120\n",
       "5        MLP   0.560824  0.374237  0.396754"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.model_performance(x.fillna(0), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
